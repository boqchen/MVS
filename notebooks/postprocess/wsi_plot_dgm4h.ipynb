{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook is used to visualize, minmax normalize and plot generated IMC from MVS model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np \n",
    "import cv2\n",
    "import glob\n",
    "import pandas as pd \n",
    "from pathlib import Path\n",
    "import openslide \n",
    "\n",
    "from PIL import Image\n",
    "import tifffile\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import sys \n",
    "import matplotlib.pyplot as plt\n",
    "root_code = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "sys.path.insert(0, root_code)\n",
    "from codebase.utils.constants import *\n",
    "from codebase.utils.raw_utils import str2bool\n",
    "from codebase.utils.eval_utils import *\n",
    "from codebase.utils.metrics import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Paths and settings ----\n",
    "project_path = '/raid/sonali/project_mvs' # UPDATE as needed\n",
    "results_path = os.path.join(project_path, 'results')\n",
    "submission_id = 'pfggdx8b_dgm4h_5GP+ASP_selected_snr_dgm4h'\n",
    "\n",
    "# -- settings to get predicted IMC wsi --\n",
    "which_set = 'external_test' # 'valid\n",
    "wsi_base = os.path.join(results_path, submission_id, which_set + '_wsis/step_350K')\n",
    "level = '6' # which imc level to use for plotting: 6,4,2\n",
    "wsi_paths_pred = glob.glob(os.path.join(wsi_base,  'level_' + level) + '/*')\n",
    "print('Number of predicted IMC images: ', len(wsi_paths_pred), wsi_paths_pred[0])\n",
    "\n",
    "# -- settings to get marker order -- \n",
    "job_args = json.load(open(Path(results_path).joinpath(submission_id, 'args.txt')))\n",
    "protein_subset = get_protein_list(job_args['protein_set'])\n",
    "channel_list = [protein2index[protein] for protein in protein_subset]\n",
    "print(protein_subset)\n",
    "\n",
    "# -- getting train quantiles -- \n",
    "cohort_quantiles_path =  Path(project_path).joinpath('data/tupro/imc_updated/agg_masked_data-raw_clip99_arc_otsu3_std_minmax_split3-r5-train_quantiles.tsv') # UPDATE as needed\n",
    "df_cohort_quantiles = pd.read_csv(cohort_quantiles_path, sep='\\t', index_col=[0])\n",
    "df_cohort_quantiles = df_cohort_quantiles.loc[['q0.95'],:]\n",
    "cohort_quantiles = df_cohort_quantiles.loc[:,protein_subset].values[0]\n",
    "print('cohort_quantiles_protein_subset: ', cohort_quantiles)\n",
    "\n",
    "# -- settings for input HE wsis -- \n",
    "HE_base = '/raid/sonali/project_mvs/downstream_tasks/immune_phenotyping/tupro/HE_new_wsi' # path where wsis are saved -- UPDATE as needed\n",
    "# HE_base = '/home/sonali/github_code/Boqi/dryrun_tcga_inference/wsi'\n",
    "level_he = 2 # 6 for tupro; 2 for TCGA \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Functions needed when have annotations for H&E ----\n",
    "def map_colors(image, colors):\n",
    "    kmeans = KMeans(n_clusters=len(pre_defined_colors), random_state=0)\n",
    "    kmeans.fit(colors)\n",
    "    kmeans.cluster_centers_ = colors\n",
    "    \n",
    "    pixels = image.reshape(-1, 3)\n",
    "    cluster_assignment = kmeans.predict(pixels.astype('double'))    \n",
    "    pixel_labels = list(map(lambda x: colors[x], cluster_assignment))\n",
    "    mapped_image = np.array(pixel_labels).reshape(image.shape).astype(np.uint8)\n",
    "\n",
    "    return mapped_image\n",
    "def get_annotation_masks(annots_path, wsi_shape):\n",
    "    # loading annotation masks: tumor and stroma within tumor compartment\n",
    "    # reading using tifffile \n",
    "    img_annots = tifffile.imread(annots_path, key=0)\n",
    "\n",
    "    # downsampling annotations as otherwise color mapping is slow  \n",
    "    img_annots = cv2.resize(img_annots, (0,0), fx=0.25, fy=0.25) \n",
    "\n",
    "    # map colors correctly to annotations \n",
    "    img_annots = map_colors(img_annots, pre_defined_colors)\n",
    "    print(img_annots.shape)\n",
    "\n",
    "    colors, _ = np.unique(img_annots.reshape(-1, img_annots.shape[-1]), axis=0, return_counts=True)\n",
    "    print('Unique colors and counts in annotated image: ', len(colors))#, colors, counts)\n",
    "    assert len(colors)<=6, \"more than 6 colors/annotations found in the image\"\n",
    "\n",
    "    # get tumor mask \n",
    "    mask_tumor = (np.all(img_annots == [255, 0, 0], axis=-1)).astype(np.uint8)\n",
    "\n",
    "    # make sure shape matches of annotations and wsi_pred \n",
    "    mask_tumor = cv2.resize(mask_tumor, (wsi_shape[1], wsi_shape[0]))\n",
    "    return mask_tumor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----getting annotations transferred from CD8 to HE ----\n",
    "# NOTE: ignore this cell for tcga as don't have annotations yet\n",
    "\n",
    "annotation_path = '/raid/sonali/project_mvs/downstream_tasks/immune_phenotyping/tupro/annotation_transfer/annotation_images_new'\n",
    "\n",
    "color_code = {(255, 255, 0): \"Whitespace\", # yellow\n",
    "(255, 0, 255): \"Positive Lymphocytes\", # pink   \n",
    "(0, 0, 0): \"Pigment\", # black\n",
    "(0, 128, 0): \"Stroma\", # green\n",
    "(255, 0, 0): \"Tumor\", # red           \n",
    "(192, 64, 0): \"Blood and necrosis\" # dirty red\n",
    "         }\n",
    "pre_defined_colors = [list(t) for t in list(color_code.keys())]\n",
    "pre_defined_colors = np.array(pre_defined_colors).astype('double')\n",
    "\n",
    "# samples with annotations on H&E WSI (tranferred from CD8)\n",
    "samples_annotations = [x.split('.')[0] for x in os.listdir(annotation_path)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling using cohorts quantiles \n",
    "def minmax_scaling(x, max_cohort):\n",
    "    return (x)/max_cohort\n",
    "\n",
    "save_plots = False\n",
    "# iterating through samples \n",
    "for wsi_path_pred in wsi_paths_pred: \n",
    "\n",
    "    # get corresponding HE image from level \n",
    "    sample = wsi_path_pred.split('/')[-1].split('.')[0]\n",
    "    wsi = openslide.open_slide(glob.glob(HE_base + '/' + sample + '*')[0])\n",
    "    level_dims = wsi.level_dimensions[level_he]\n",
    "    wsi_he = np.array(wsi.read_region((0, 0), level_he, level_dims))[:,:,0:3]\n",
    "    print(wsi_he.shape)\n",
    "\n",
    "    # get annotation mask if possible -- ignore for tcga for now \n",
    "    if sample in samples_annotations: \n",
    "        print(sample)\n",
    "        annots_path = os.path.join(annotation_path, sample + '.tif')\n",
    "        mask_tumor = get_annotation_masks(annots_path, wsi_he.shape)\n",
    "        print('mask_tumor: ', mask_tumor.shape, np.amax(mask_tumor), np.amin(mask_tumor))\n",
    "\n",
    "        # overlay tumor mask on HE\n",
    "        mask_tumor = cv2.cvtColor((mask_tumor*255).astype(np.uint8), cv2.COLOR_GRAY2RGB)\n",
    "        print('mask_tumor: ', mask_tumor.shape)\n",
    "\n",
    "        # Use cv2.addWeighted() to overlay the mask on the image\n",
    "        wsi_he_overlay = cv2.addWeighted(wsi_he, 0.6, mask_tumor, 0.4, 0)\n",
    "        print('wsi_he_overlay: ', wsi_he_overlay.shape)\n",
    "\n",
    "    # load wsi imc pred \n",
    "    wsi_pred = np.load(wsi_path_pred)\n",
    "    print(wsi_pred.shape)\n",
    "    # scaling \n",
    "    wsi_pred = np.apply_along_axis(minmax_scaling, 2, wsi_pred, max_cohort=cohort_quantiles)\n",
    "    print(wsi_pred.shape)\n",
    "\n",
    "    # --- combining markers for plot ----\n",
    "    pred_Tcells = ['CD8a', 'CD3']\n",
    "    pred_Bcells = ['CD20']\n",
    "    pred_tumor = ['S100', 'MelanA', 'gp100']\n",
    "    # -- 1. Combining tumor, B cells and T cells -- \n",
    "    # tumor\n",
    "    wsi_pred_tumor = np.zeros(wsi_pred.shape[0:2], dtype=float)\n",
    "    for protein in pred_tumor:\n",
    "        wsi_pred_tumor = np.maximum(wsi_pred_tumor, wsi_pred[:,:,protein_subset.index(protein)])\n",
    "    # B cells \n",
    "    wsi_pred_Bcells = np.zeros(wsi_pred.shape[0:2], dtype=float)\n",
    "    for protein in pred_Bcells:\n",
    "        wsi_pred_Bcells = np.maximum(wsi_pred_Bcells, wsi_pred[:,:,protein_subset.index(protein)])\n",
    "    # T cells \n",
    "    wsi_pred_Tcells = np.zeros(wsi_pred.shape[0:2], dtype=float)\n",
    "    for protein in pred_Tcells:\n",
    "        wsi_pred_Tcells = np.maximum(wsi_pred_Tcells, wsi_pred[:,:,protein_subset.index(protein)])\n",
    "    # tumor, Bcells, Tcells\n",
    "    wsi_pred_viz1 = np.dstack((wsi_pred_tumor, wsi_pred_Bcells, wsi_pred_Tcells))\n",
    "    print('wsi_pred_viz1: ', wsi_pred_viz1.shape)\n",
    "\n",
    "    # -- 2. Combining tumor,HLA-DR and HLA-ABC -- \n",
    "    # tumor\n",
    "    wsi_pred_tumor = np.zeros(wsi_pred.shape[0:2], dtype=float)\n",
    "    for protein in pred_tumor:\n",
    "        wsi_pred_tumor = np.maximum(wsi_pred_tumor, wsi_pred[:,:,protein_subset.index(protein)])\n",
    "    # combining tumor, HLA-DR, HLA-ABC\n",
    "    wsi_pred_viz2 = np.dstack((wsi_pred_tumor, wsi_pred[:,:,protein_subset.index('HLA-DR')], wsi_pred[:,:,protein_subset.index('HLA-ABC')]))\n",
    "    print('wsi_pred_viz2: ', wsi_pred_viz2.shape)\n",
    "\n",
    "    # -- 3. Combining tumor, CD16, CD31 -- \n",
    "    # tumor\n",
    "    wsi_pred_tumor = np.zeros(wsi_pred.shape[0:2], dtype=float)\n",
    "    for protein in pred_tumor:\n",
    "        wsi_pred_tumor = np.maximum(wsi_pred_tumor, wsi_pred[:,:,protein_subset.index(protein)])\n",
    "    # combining tumor, HLA-DR, HLA-ABC\n",
    "    wsi_pred_viz3 = np.dstack((wsi_pred_tumor, wsi_pred[:,:,protein_subset.index('CD16')], wsi_pred[:,:,protein_subset.index('CD31')]))\n",
    "    print('wsi_pred_viz3: ', wsi_pred_viz3.shape)\n",
    "\n",
    "    # Plotting \n",
    "    fig = plt.figure(figsize=(40, 20))\n",
    "\n",
    "    plt.subplot(1, 4, 1) \n",
    "    plt.imshow(wsi_he)#(wsi_he_overlay)\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 4, 2)  \n",
    "    plt.imshow(wsi_pred_viz1)\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 4, 3)\n",
    "    plt.imshow(wsi_pred_viz2)\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 4, 4) \n",
    "    plt.imshow(wsi_pred_viz3)\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplots_adjust(wspace=0.01, hspace=0)\n",
    "\n",
    "    # save \n",
    "    if save_plots: \n",
    "        save_path = os.path.join(os.getcwd(), 'plots') # change as needed\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "        plt.savefig(os.path.join(save_path, sample+'-wsi_dgm4h.pdf'), bbox_inches='tight', dpi=300,  pad_inches = 0)\n",
    "        \n",
    "    plt.show() \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
