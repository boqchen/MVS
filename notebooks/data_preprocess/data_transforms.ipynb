{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed228016",
   "metadata": {},
   "source": [
    "### Code for updated data transformations and augmentations and visualise them to change "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2faeb4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms as T\n",
    "import torchvision.transforms.functional as TF\n",
    "import random\n",
    "from typing import Sequence\n",
    "\n",
    "import sys \n",
    "root_code = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "sys.path.insert(0, root_code)\n",
    "\n",
    "from codebase.utils.constants import *\n",
    "from codebase.utils.raw_utils import *\n",
    "from codebase.utils.dataset_utils import clean_train_val_test_sep_for_manual_aligns_ordered_by_quality, filter_and_transform\n",
    "\n",
    "from codebase.utils.zipper import do_zip\n",
    "from codebase.experiments.cgan3.training_helpers import *\n",
    "from codebase.experiments.cgan3.network import * #Translator, Discriminator\n",
    "from codebase.experiments.cgan3.loaders import CGANDataset\n",
    "from codebase.utils.eval_utils import get_protein_list\n",
    "from codebase.utils.HEtransform_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9facb9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61278e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "protein_set = 'reduced_ext'\n",
    "patch_size = 256\n",
    "cv_split = 'split0'\n",
    "imc_prep_seq = 'raw_clip99_arc_otsu3'\n",
    "project_path = '/cluster/work/grlab/projects/projects2021-multivstain/'\n",
    "data_path = '/cluster/work/grlab/projects/projects2021-multivstain/data/tupro/'\n",
    "standardize_imc = True\n",
    "scale01_imc = True\n",
    "batch_size = 8\n",
    "\n",
    "train_aligns = get_aligns(project_path, cv_split=cv_split, protein_set=protein_set, aligns_set='train')\n",
    "protein_subset = get_protein_list(protein_set)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a14fa1",
   "metadata": {},
   "source": [
    "### 1. Data loader v2 \n",
    "- modifying the current setup with transform functions and probability \n",
    "- flow: data loader with transforms --> batch to device\n",
    "- IMC transforms for channelwise minmax std; shared transforms for flips and rotations; HE transforms for color and affine transforms  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e47a48",
   "metadata": {},
   "source": [
    "#### 2.1 IMC transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55a3d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def IMC_transforms(standardize_data, minmax_data, cohort_stats_file, channel_list):\n",
    "    '''\n",
    "    The function returns the nn.sequential necessary for normalisation of IMC data\n",
    "    standardize_data: True/False based on if need to standardise IMC data  \n",
    "    minmax_data: True/False based on if need to apply minmax to IMC data\n",
    "    cohort_stats_file: path where the stats of the split reside \n",
    "    channel_list: the desired markers in the multiplex   \n",
    "    '''\n",
    "    if standardize_data or minmax_data: \n",
    "        cohort_stats = pd.read_csv(cohort_stats_file, sep='\\t', index_col=[0])\n",
    "\n",
    "    if standardize_data:\n",
    "        # load cohort stats based on imc preprocessing steps (naming convention)\n",
    "        mean_mat = cohort_stats['mean_cohort'][channel_list]\n",
    "        std_mat = cohort_stats['std_cohort'][channel_list]\n",
    "\n",
    "    if minmax_data:\n",
    "        min_col = 'min_stand_cohort' if standardize_data else 'min_cohort'\n",
    "        max_col = 'max_stand_cohort' if minmax_data else 'max_cohort'\n",
    "        min_mat = cohort_stats[min_col][channel_list]\n",
    "        max_mat = cohort_stats[max_col][channel_list]\n",
    "\n",
    "    def default(val, def_val):\n",
    "        return def_val if val is None else val\n",
    "\n",
    "    imc_transforms = []\n",
    "    if standardize_data: \n",
    "        imc_transforms.append(\n",
    "        T.Normalize(mean_mat, std_mat)\n",
    "        )\n",
    "\n",
    "    if minmax_data: \n",
    "        imc_transforms.append(\n",
    "        T.Normalize(min_mat, (max_mat-min_mat))\n",
    "        )\n",
    "    imc_transform_default = nn.Sequential(*imc_transforms)\n",
    "    imc_transforms = default(None, imc_transform_default)  \n",
    "    return imc_transforms\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83cd791b",
   "metadata": {},
   "source": [
    "#### 2.2 Shared transforms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4b2919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- SHARED TRANSFORMS -----  \n",
    "def shared_transforms(img1, img2, p=0.5):\n",
    "    '''\n",
    "    The function contains the possible transformation that could be applied simultaneously to H&E and IMC data\n",
    "    eg: random horizontal or vertical flip, random rotation for angles multiple of 90 degress\n",
    "    img1: H&E ROI (expected)\n",
    "    img2: IMC ROI (expected)\n",
    "    p: the probability with which the transformation should be applied \n",
    "    '''\n",
    "    # Random horizontal flipping\n",
    "    if random.random() < p:\n",
    "        img1 = TF.hflip(img1)\n",
    "        img2 = TF.hflip(img2)\n",
    "\n",
    "    # Random vertical flipping\n",
    "    if random.random() < p:\n",
    "        img1 = TF.vflip(img1)\n",
    "        img2 = TF.vflip(img2)\n",
    "        \n",
    "    # Random 90 degree rotation\n",
    "    if random.random() < p:\n",
    "        angle = random.choice([90, 180, 270])\n",
    "        img1 = TF.rotate(img1, angle)\n",
    "        img2 = TF.rotate(img2, angle) \n",
    "    return img1, img2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db4a343",
   "metadata": {},
   "source": [
    "#### 2.3 HE transforms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8ca407",
   "metadata": {},
   "outputs": [],
   "source": [
    "def HE_transforms(img, p=[0.0, 0.5, 0.5]):\n",
    "    '''\n",
    "    The function contains the possible transformation that could be applied to H&E ROIs\n",
    "    This includes \n",
    "    eg: random horizontal or vertical flip, random rotation for angles multiple of 90 degress\n",
    "    img1: H&E ROI (expected)\n",
    "    img2: IMC ROI (expected)\n",
    "    p: the probability with which the transformation should be applied \n",
    "    '''\n",
    "    # Random color jitter\n",
    "    if random.random() < p[0]:\n",
    "#         jitter = T.ColorJitter(brightness=.34, hue=.15)\n",
    "        jitter = T.ColorJitter(brightness=.15, hue=.05, saturation=0.15)\n",
    "        img = jitter(img)\n",
    "\n",
    "    # Random HED jitter \n",
    "    if random.random() < p[1]:\n",
    "        img = torch.permute(img, (1, 2, 0)) # channel first to last    \n",
    "#         hedjitter = HEDJitter(theta=0.05) # from HEtransform_utils\n",
    "        hedjitter = HEDJitter(theta=0.01) # from HEtransform_utils\n",
    "\n",
    "        img = hedjitter(img) \n",
    "\n",
    "    # Random affine transform\n",
    "    if random.random() < p[2]:\n",
    "        if not img.shape[2]==3: \n",
    "            img = torch.permute(img, (1, 2, 0)) # channel first to last    \n",
    "        randomaffine = RandomAffineCV2(alpha=0.02) # from HEtransform_utils\n",
    "        img = randomaffine(img) \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c0acef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.manual_seed(0)\n",
    "# random.seed(0)\n",
    "# np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6821290",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ----- New version of dataloader -----\n",
    "class CGANDataset_v2(Dataset):\n",
    "    def __init__(self, project_path, align_results: list, name: str, data_path: str, protein_subset=PROTEIN_LIST_MVS, patch_size=400, imc_prep_seq='raw', cv_split='split0', standardize_imc=True, scale01_imc=True, factor_len_dataloader=8.0, which_HE='new', p_flip_jitter_hed_affine=[0.5,0.0,0.5,0.5]):\n",
    "        super(CGANDataset_v2, self).__init__()\n",
    "\n",
    "        self.project_path = project_path\n",
    "        self.align_results = align_results\n",
    "        self.name = name\n",
    "        self.data_path = data_path\n",
    "        self.patch_size = patch_size\n",
    "        self.channel_list = [protein2index[prot_name] for prot_name in protein_subset]\n",
    "        self.cv_split = cv_split\n",
    "        \n",
    "        self.HE_ROI_STORAGE = get_he_roi_storage(self.data_path, which_HE)      \n",
    "        self.IMC_ROI_STORAGE = get_imc_roi_storage(self.data_path, imc_prep_seq, standardize_imc, scale01_imc, cv_split)\n",
    "         \n",
    "        # if need to std or minmax IMC data \n",
    "        standardize_data = standardize_imc and ('std' not in self.IMC_ROI_STORAGE) \n",
    "        minmax_data = scale01_imc and ('minmax' not in self.IMC_ROI_STORAGE) \n",
    "        cohort_stats_file = os.path.join(project_path, COHORT_STATS_PATH, cv_split, 'imc_rois_'+imc_prep_seq+'-agg_stats.tsv')\n",
    "\n",
    "        self.imc_transforms = IMC_transforms(standardize_data, minmax_data, cohort_stats_file, self.channel_list)\n",
    "        self.shared_transforms = shared_transforms\n",
    "        self.he_transforms = HE_transforms\n",
    "\n",
    "        self.p_shared = p_flip_jitter_hed_affine[0]\n",
    "        self.p_jitter = p_flip_jitter_hed_affine[1]\n",
    "        self.p_hed = p_flip_jitter_hed_affine[2]\n",
    "        self.p_affine = p_flip_jitter_hed_affine[3]\n",
    "\n",
    "        assert len(self.align_results) > 0, \"Dataset received empty list of alignment results !\"\n",
    "        print(self.name + \" has \", len(self.align_results), \" alignment results !\")\n",
    "\n",
    "        # an estimation of number of training samples \n",
    "        self.num_samples = int(len(self.align_results) * ((1000 // (self.patch_size // 2)) ** 2) * factor_len_dataloader)\n",
    "        print(self.name + \" has \", self.num_samples, \" training samples !\")\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "    \n",
    "    def __getitem__(self, idx):  # CAUTION idx argument is ignored, dataset is purely random !\n",
    "        \n",
    "        # load from disk:\n",
    "        ar = random.choice(self.align_results)\n",
    "        he_roi = np.load(os.path.join(self.HE_ROI_STORAGE, ar[\"sample\"] + \"_\" + ar[\"ROI\"] + \".npy\"), mmap_mode='r')\n",
    "        imc_roi = np.load(os.path.join(self.IMC_ROI_STORAGE, ar[\"sample\"] + \"_\" + ar[\"ROI\"] + \".npy\"), mmap_mode='r')\n",
    "        \n",
    "        # only keep channels that we need:\n",
    "        imc_roi = imc_roi[:, :, self.channel_list]\n",
    "        \n",
    "        augment_x_offset = random.randint(0, 1000 - self.patch_size)\n",
    "        augment_y_offset = random.randint(0, 1000 - self.patch_size)\n",
    "\n",
    "        he_patch = he_roi[4 * augment_y_offset: 4 * augment_y_offset + 4 * self.patch_size,\n",
    "                          4 * augment_x_offset: 4 * augment_x_offset + 4 * self.patch_size, :]\n",
    "\n",
    "        imc_patch = imc_roi[augment_y_offset: augment_y_offset + self.patch_size,\n",
    "                            augment_x_offset: augment_x_offset + self.patch_size, :]   \n",
    "\n",
    "        he_patch = he_patch.transpose((2, 0, 1)) \n",
    "        imc_patch = imc_patch.transpose((2, 0, 1)) \n",
    "        he_patch = torch.from_numpy(he_patch.astype(np.float32, copy=False))\n",
    "        imc_patch = torch.from_numpy(imc_patch.astype(np.float32, copy=False))\n",
    "        \n",
    "        he_patch, imc_patch = self.shared_transforms(he_patch, imc_patch, p=self.p_shared)\n",
    "        imc_patch =  self.imc_transforms(imc_patch)\n",
    "        he_patch_T = self.he_transforms(he_patch, p=[self.p_jitter, self.p_hed, self.p_affine])\n",
    "\n",
    "        if not he_patch.shape[0]==3: \n",
    "            he_patch = torch.from_numpy(he_patch.transpose((2, 0, 1)))\n",
    "        if not he_patch_T.shape[0]==3: \n",
    "            he_patch_T = torch.from_numpy(he_patch_T.transpose((2, 0, 1)))\n",
    "\n",
    "        return {'he_patch': he_patch.to(torch.float), \n",
    "                'imc_patch': imc_patch.to(torch.float),\n",
    "                'he_patch_T': he_patch_T.to(torch.float),\n",
    "                'sample': ar['sample'], 'roi': ar['ROI'], 'x_offset': augment_x_offset, 'y_offset': augment_y_offset\n",
    "               }    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e754bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "standardize_imc = True\n",
    "scale01_imc = True \n",
    "which_HE = 'new'\n",
    "\n",
    "prob_flip_jitter_hed_affine = '0.5,1,1,0.5'\n",
    "p_flip_jitter_hed_affine = list(map(float, prob_flip_jitter_hed_affine.split(',')))\n",
    "print(p_flip_jitter_hed_affine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9eaa57",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_ds = CGANDataset_v2(project_path, align_results=train_aligns[0:30],\n",
    "                    name=\"Train\",\n",
    "                    data_path=data_path,\n",
    "                    patch_size=patch_size,\n",
    "                    protein_subset=protein_subset,\n",
    "                    imc_prep_seq=imc_prep_seq,\n",
    "                    cv_split=cv_split,\n",
    "                    standardize_imc=standardize_imc,\n",
    "                    scale01_imc=scale01_imc,\n",
    "                    factor_len_dataloader=1, \n",
    "                    which_HE=which_HE, \n",
    "                    p_flip_jitter_hed_affine=p_flip_jitter_hed_affine)\n",
    "\n",
    "print('Loaded data')\n",
    "trainloader = DataLoader(train_ds,\n",
    "                         batch_size=batch_size,\n",
    "                         shuffle=True,\n",
    "                         pin_memory=True,\n",
    "                         num_workers=8, \n",
    "                         drop_last=True)\n",
    "\n",
    "print('HE_ROI_STORAGE: ', train_ds.HE_ROI_STORAGE)\n",
    "print('IMC_ROI_STORAGE: ', train_ds.IMC_ROI_STORAGE)\n",
    "\n",
    "print(train_ds.p_shared, train_ds.p_jitter, train_ds.p_hed, train_ds.p_affine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d62b1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get batch of data \n",
    "batch = next(iter(trainloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ee1cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(batch['he_patch'].shape, batch['he_patch'].type(), torch.aminmax(batch['he_patch'][0]))\n",
    "print(batch['he_patch_T'].shape, batch['he_patch_T'].type(), torch.aminmax(batch['he_patch_T'][0]))\n",
    "print(batch['imc_patch'].shape, batch['imc_patch'].type(), torch.aminmax(batch['imc_patch'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb48074b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualise data\n",
    "\n",
    "plt.figure(figsize = (20,5))\n",
    "plt.axis('off')\n",
    "for i in range(8):\n",
    "    plt.subplot(2, 8, i+1)\n",
    "    plt.imshow(torch.permute(batch['he_patch'][i], (1, 2, 0)))\n",
    "    plt.axis('off')\n",
    "\n",
    "for i in range(8):\n",
    "    plt.subplot(2, 8, i+1+8)\n",
    "    plt.imshow(torch.permute(batch['he_patch_T'][i], (1, 2, 0)))\n",
    "#     plt.imshow(torch.permute(batch['imc_patch'][i], (1, 2, 0))[:,:,6])\n",
    "    plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb33df84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d23416",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0660c613",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
